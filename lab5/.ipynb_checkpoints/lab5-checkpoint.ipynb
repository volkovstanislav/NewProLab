{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import string\n",
    "import pymorphy2\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "path = \"/data/share/lab05data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорт и обработка тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_id = [1, 3587, 770, 3593, 3084, 3607, 536, 1561, 2588, 3931, 2079, 2481, 2406, 1580, 2605, 2101, 55, 1081, 62, 63, 3649, 3139, 581, 70, 3143, 1098, 1099, 589, 2134, 88, 2649, 357, 2139, 1117, 358, 1634, 189, 1644, 109, 3184, 3188, 2166, 2682, 3198, 3125, 3203, 1669, 646, 3719, 1560, 144, 3730, 1174, 3223, 3738, 3739, 1183, 3744, 1188, 1701, 711, 680, 535, 2174, 1714, 799, 695, 1720, 2462, 1211, 701, 702, 1215, 630, 194, 3783, 3784, 3279, 1150, 2259, 724, 383, 3800, 2265, 3293, 3296, 740, 1767, 3820, 3822, 3824, 241, 3317, 1270, 2006, 1281, 231, 812, 2311, 2830, 2323, 789, 2010, 409, 133, 1311, 2343, 3368, 2860, 3886, 2864, 307, 2357, 2358, 2954, 2362, 3901, 1343, 822, 1345, 1347, 324, 3639, 2377, 312, 3405, 2896, 3300, 3418, 859, 861, 352, 3426, 356, 3429, 2918, 658, 2924, 1909, 2423, 1344, 1407, 2436, 1928, 1418, 3566, 3481, 1428, 406, 1432, 2457, 2288, 2461, 1691, 2977, 2467, 1956, 2981, 2982, 2984, 1961, 939, 429, 2992, 433, 3067, 2036, 2485, 444, 1469, 3920, 3524, 455, 504, 2028, 3025, 3538, 2517, 3542, 2521, 869, 3547, 336, 3038, 2531, 998, 2535, 2025, 1704, 2029, 2030, 510, 1521, 2548, 1525, 870, 836, 1024, 2731, 2646]\n",
    "\n",
    "rows_list_test = []\n",
    "for i in text_id:\n",
    "    # test\n",
    "    text_file = open(path + \"/test_\" + str(i) + \".txt\", \"r\")\n",
    "    if text_file.mode == 'r':\n",
    "        contents =text_file.read()\n",
    "    row = {\"id\":i, \"text\":contents}\n",
    "    rows_list_test.append(row)\n",
    "\n",
    "df_text = pd.DataFrame(rows_list_test, columns=[\"id\",\"text\"])\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_files = glob.glob(path + \"/base_*.txt\")\n",
    "rows_list_base = []\n",
    "for file in txt_files:    \n",
    "    open_file = open(file, \"r\")\n",
    "    if open_file.mode == 'r':\n",
    "        contents =open_file.read()\n",
    "    row = {\"text\":contents}\n",
    "    rows_list_base.append(row)\n",
    "\n",
    "df_text_base = pd.DataFrame(rows_list_base, columns=[\"text\"])\n",
    "df_text_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    \"\"\"Удалим html теги из текста\"\"\"\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)\n",
    "\n",
    "def remove_special_chars(text):\n",
    "    \"\"\"Удалим все кроме букв и пробелов\"\"\"\n",
    "    clean = re.sub('[^А-Яа-я[\" \"]]+', '', text)\n",
    "    clean = clean.translate(str.maketrans('', '', string.punctuation))\n",
    "    return clean\n",
    "\n",
    "def remove_digit_from_text(text):\n",
    "    \"\"\"Удалим цифры из текста\"\"\"\n",
    "    clean = re.sub(r'\\d+', '', text)\n",
    "    return clean\n",
    "\n",
    "def transform_to_lower(text):\n",
    "    \"\"\"Приведем весь текст к нижнему регистру\"\"\"\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text[\"text\"] = df_text[\"text\"].apply(lambda x: remove_html_tags(x))\n",
    "df_text[\"text\"] = df_text[\"text\"].apply(lambda x: remove_special_chars(x))\n",
    "df_text[\"text\"] = df_text[\"text\"].apply(lambda x: transform_to_lower(x))\n",
    "df_text[\"text\"] = df_text[\"text\"].apply(lambda x: remove_digit_from_text(x))\n",
    "\n",
    "df_text_base[\"text\"] = df_text_base[\"text\"].apply(lambda x: remove_html_tags(x))\n",
    "df_text_base[\"text\"] = df_text_base[\"text\"].apply(lambda x: remove_special_chars(x))\n",
    "df_text_base[\"text\"] = df_text_base[\"text\"].apply(lambda x: transform_to_lower(x))\n",
    "df_text_base[\"text\"] = df_text_base[\"text\"].apply(lambda x: remove_digit_from_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Токенизируем\n",
    "df_text[\"text\"] = df_text[\"text\"].apply(lambda x: word_tokenize(x))\n",
    "df_text_base[\"text\"] = df_text_base[\"text\"].apply(lambda x: word_tokenize(x))\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем стоп-слова\n",
    "df_text[\"text\"] = df_text[\"text\"].apply(lambda word_list: [word for word in word_list if word not in stopwords.words('russian')])\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#проведем лемматизацию\n",
    "pymorph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "df_text[\"text\"] = df_text[\"text\"].apply(lambda word_list: [pymorph.parse(word)[0].normal_form for word in word_list])\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загружаем тексты известных тематик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
